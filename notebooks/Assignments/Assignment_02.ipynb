{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d8158dfddb2ac72",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "In this assignment, you will continue with the Bigram Language Model from the Lecture. Make the training loop and inference for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011cbf15834af26",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Set the random seed for reproducibility.\n",
    "\n",
    "    Args:\n",
    "        seed (int): The seed value to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Random seed set to {seed}\")\n",
    "\n",
    "\n",
    "def configure_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Configure the device for training.\n",
    "\n",
    "    Returns:\n",
    "        torch.device: The device to use for training.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        print(f\"Running on {num_gpu} {torch.cuda.get_device_name()} GPU(s)\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(f\"Running on {device}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(f\"Running on {device}\")\n",
    "    return device\n",
    "\n",
    "\n",
    "def load_text(file_path: str, encoding: str = 'utf-8') -> str:\n",
    "    \"\"\"\n",
    "    Load and read text data from a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the text file.\n",
    "        encoding (str, optional): File encoding. Defaults to 'utf-8'.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the text file.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as f:\n",
    "        text = f.read()\n",
    "\n",
    "    print(f\"Loaded text data from {file_path} (length: {len(text)} characters).\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a0b5274f4dca2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1253f6800c36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BigramConfig: # 프로젝트의 설정값들을 하나의 객체에 저장하는 역할\n",
    "    root_dir: str = os.getcwd() + \"/\"\n",
    "    dataset_path: str = \"/names.txt\"\n",
    "\n",
    "    # Tokenizer\n",
    "    vocab_size: int = 0  # Set later\n",
    "\n",
    "    seed: int = 101\n",
    "    \n",
    "config = BigramConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726a09b7e375389",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4d38445588cdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 101\n"
     ]
    }
   ],
   "source": [
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74be7e01434a14b",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e86ea6f15f11b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text data from /Users/jimni/Downloads//names.txt (length: 228145 characters).\n"
     ]
    }
   ],
   "source": [
    "names = load_text(config.root_dir + config.dataset_path).splitlines()\n",
    "# 불러온 텍스트 데이터를 줄 단위로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aff6f7e1bbade4",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed24c0db0ce9da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add special token\n",
    "names = [\".\" + name + \".\" for name in names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e38655c11342dd",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f768e619dfb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [chr(i) for i in range(97, 123)]  # all alphabet characters\n",
    "chars.insert(0, \".\")  # Add special token\n",
    "config.vocab_size = len(chars)\n",
    "str2idx = {char: idx for idx, char in enumerate(chars)} # 문자를 인덱스로 변환\n",
    "idx2str = {idx: char for char, idx in str2idx.items()} # 인덱스를 문자로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4e1dda633584d",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "523dd8edb6b3e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "W = torch.randn(config.vocab_size, config.vocab_size, requires_grad=True)\n",
    "b = torch.randn(config.vocab_size, requires_grad=True)\n",
    "params = [W, b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ca7979aafb68a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6125c93c9c7519",
   "metadata": {},
   "source": [
    "#### Task 1: Train Bigram Language Model (Neural Network Approach)\n",
    "\n",
    "Make the training loop for the Bigram Language Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8f5165e72e37f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of Input, Target pairs\n",
    "inputs, targets = [], []\n",
    "for name in names:\n",
    "    for char1, char2 in zip(name, name[1:]):\n",
    "        input = str2idx[char1]\n",
    "        target = str2idx[char2]\n",
    "        inputs.append(input)\n",
    "        targets.append(target)\n",
    "\n",
    "# Convert to tensor\n",
    "inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "targets = torch.tensor(targets, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe57ba03f098d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Input, Target pairs: 228146\n",
      "Input shape: torch.Size([228146])\n",
      "Target shape: torch.Size([228146])\n",
      "First (Input, Target): (0, 5)\n",
      "Second (Input, Target): (5, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Input, Target pairs: {len(inputs)}\")\n",
    "print(f\"Input shape: {inputs.shape}\")\n",
    "print(f\"Target shape: {targets.shape}\")\n",
    "print(f\"First (Input, Target): ({inputs[0]}, {targets[0]})\")\n",
    "print(f\"Second (Input, Target): ({inputs[1]}, {targets[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baab50fd5515e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# One-hot encode the input tensor.                                             #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "inputs_encoded = F.one_hot(inputs, num_classes=config.vocab_size)\n",
    "''' One-hot 함수는 범주형 데이터를 기계 학습 모댈이 이해할 수 있는 이진 벡터로 변환하는 기법\n",
    "각 범주를 고유한 인덱스로 지정한 후, 해당 인덱스 위치에 1을 두고 나머지 위치에는 0을 채우는 방식으로 작동'''\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# Convert data type to float\n",
    "inputs_encoded = inputs_encoded.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ef07b0b820e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10, Loss 2.8777\n",
      "Step 20, Loss 2.7156\n",
      "Step 30, Loss 2.6413\n",
      "Step 40, Loss 2.5989\n",
      "Step 50, Loss 2.5718\n",
      "Step 60, Loss 2.5532\n",
      "Step 70, Loss 2.5397\n",
      "Step 80, Loss 2.5294\n",
      "Step 90, Loss 2.5214\n",
      "Step 100, Loss 2.5150\n"
     ]
    }
   ],
   "source": [
    "# Training Loop (신경망 학습 루프)\n",
    "steps = 100\n",
    "lr = 10\n",
    "\n",
    "for step in range(1, steps + 1):\n",
    "    # Forward pass\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Implement the forward pass.                                                  #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    logits = inputs_encoded @ W + b  \n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    '''입력값을 가중치 행렬 W와 평향 b에 의해 선형 변환함\n",
    "    softmax 함수를 적용해 각 출력 노드의 확률 분포를 계산함'''\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    # loss\n",
    "    log_probs = torch.log(probs + 1e-9)  # Add small value to prevent log(0)\n",
    "    loss = -log_probs[torch.arange(len(targets)), targets].mean()\n",
    "    # 모델이 예측한 확률의 로그 값을 취한 후, 정답 인덱스에 해당하는 log-probability의 음수를 평균내어 loss값 구함\n",
    "    \n",
    "    # Backward pass\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Implement the backward pass.                                                 #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    loss.backward()\n",
    "    '''loss.backward()를 호출해 PyTorch의 자동 미분 시스템이 각 파라미터 (W, b)에 대한 기울기를 계산함'''\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    # Update weights\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Update the weights of the model using the gradients.                         #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad\n",
    "            param.grad.zero_()\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(f\"Step {step}, Loss {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d956fef0a027963",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786f852b486b92cb",
   "metadata": {},
   "source": [
    "#### Task 2: Generate a Name\n",
    "\n",
    "Create a function to generate a name using the trained Bigram Language Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b31dfacd08b51cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "am\n",
      "kasskve\n",
      "aaion\n",
      "are\n"
     ]
    }
   ],
   "source": [
    "# Create a function to generate a name\n",
    "def generate_name():\n",
    "    new_name = []\n",
    "    start_idx = str2idx[\".\"]\n",
    "    \n",
    "    while True:\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # 1. Forward pass                                                              #\n",
    "        # 2. Sample the next token                                                     #\n",
    "        # 3. Decode the token                                                          #\n",
    "        # 4. Update the start_idx                                                      #\n",
    "        # 5. Break if the next character is \".\"                                        #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # One-hot encode the current token\n",
    "        x = F.one_hot(torch.tensor([start_idx]), num_classes=config.vocab_size).float()\n",
    "        \n",
    "        # Compute logits and obtain probabilities\n",
    "        logits = x @ W + b\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Sample the next token using multinomial sampling\n",
    "        next_idx = torch.multinomial(probs, num_samples=1).item()\n",
    "        \n",
    "        # Decode the token back to its character representation\n",
    "        next_char = idx2str[next_idx]\n",
    "        \n",
    "        # Update start_idx to the sampled token for the next iteration\n",
    "        start_idx = next_idx\n",
    "        \n",
    "        # If the sampled token is the terminal marker, break the loop;\n",
    "        # Otherwise, append it to the new_name list.\n",
    "        if next_char == \".\":\n",
    "            break\n",
    "        new_name.append(next_char)\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    return ''.join(new_name)\n",
    "\n",
    "# Generate 5 names\n",
    "for _ in range(5):\n",
    "    print(generate_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d00faaddbe4b44",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "\n",
    "We have already made our own custom auto-grad Tensor class. Let's use it!\n",
    "\n",
    "Train the Bigram Language Model using our custom auto-grad Tensor class.\n",
    "\n",
    "**Do not use any built-in PyTorch functions.** (other deep learning libraries are also prohibited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6f26efc1212bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, data, _children=(), _operation=''):\n",
    "        self.data = data\n",
    "        self._prev = set(_children)\n",
    "        self.gradient = 0\n",
    "        self._backward = lambda: None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"tensor=({self.data})\"\n",
    "\n",
    "    def __add__(self, other):  # self + other\n",
    "        output = Tensor(self.data + other.data, (self, other), '+')\n",
    "        def _backward():\n",
    "            self.gradient = 1 * output.gradient\n",
    "            other.gradient = 1 * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def __mul__(self, other):  # self * other\n",
    "        output = Tensor(self.data * other.data, (self, other), '*')\n",
    "        def _backward():\n",
    "            self.gradient = other.data * output.gradient\n",
    "            other.gradient = self.data * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def tanh(self):  # tanh(self)\n",
    "        output = Tensor(math.tanh(self.data), (self,), 'tanh')\n",
    "        def _backward():\n",
    "            self.gradient = (1.0 - math.tanh(self.data) ** 2) * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def __pow__(self, power):  # self ** power\n",
    "        assert isinstance(power, (int, float)), \"Power must be an int or a float\"\n",
    "        output = Tensor(self.data ** power, (self,), f'**{power}')\n",
    "        def _backward():\n",
    "            self.gradient = power * (self.data ** (power - 1)) * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "        self.gradient = 1\n",
    "        for node in reversed(topo):\n",
    "            node._backward()\n",
    "\n",
    "    def __neg__(self): # -self\n",
    "        return self * Tensor(-1.0)\n",
    "\n",
    "    def __sub__(self, other): # self - other\n",
    "        return self + (-other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3b7815ada66df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
